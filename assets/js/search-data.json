{
  
    
        "post0": {
            "title": "COVID new model",
            "content": "path=Path(&#39;/home/staff/xin/Downloads/leafdisease/segmented/&#39;) . src=ImageList.from_folder(path).split_by_rand_pct(seed=2).label_from_folder() . data=(src.transform(get_transforms(),size=256).databunch(bs=8).normalize(imagenet_stats)) . data.show_batch() . # from torchvision import models import torchvision from Decoder import conv3x3,ConvRelu,DecoderBlock,DecoderBlockV2 . class UnetResnet34(nn.Module): def __init__(self, num_classes=2, num_filters=32, pretrained=True, is_deconv=False): &quot;&quot;&quot; :param num_classes: :param num_filters: :param pretrained: False - no pre-trained network is used True - encoder is pre-trained with resnet34 :is_deconv: False: bilinear interpolation is used in decoder True: deconvolution is used in decoder &quot;&quot;&quot; super().__init__() self.num_classes = num_classes self.mean = (0.485, 0.456, 0.406) self.std = (0.229, 0.224, 0.225) self.pool = nn.MaxPool2d(2, 2) self.encoder = torchvision.models.resnet34(pretrained=pretrained) self.encoder2 = torchvision.models.resnet34(pretrained=pretrained) self.relu = nn.ReLU(inplace=True) self.conv1 = nn.Sequential(self.encoder.conv1, self.encoder.bn1, self.encoder.relu, self.pool) self.conv2 = self.encoder.layer1 self.conv3 = self.encoder.layer2 self.conv4 = self.encoder.layer3 self.conv5 = self.encoder.layer4 self.avgpool = self.encoder.avgpool self.fc=nn.Linear(in_features=512, out_features=data.c, bias=True) self.center = DecoderBlockV2(512, num_filters * 8 * 2, num_filters * 8, is_deconv) self.dec5 = DecoderBlockV2(512 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv) self.dec4 = DecoderBlockV2(256 + num_filters * 8, num_filters * 8 * 2, num_filters * 8, is_deconv) self.dec3 = DecoderBlockV2(128 + num_filters * 8, num_filters * 4 * 2, num_filters * 2, is_deconv) self.dec2 = DecoderBlockV2(64 + num_filters * 2, num_filters * 2 * 2, num_filters * 2 * 2, is_deconv) self.dec1 = DecoderBlockV2(num_filters * 2 * 2, num_filters * 2 * 2, num_filters, is_deconv) self.dec0 = conv_layer(num_filters, num_filters) self.trans = conv_layer(num_filters,2,1,leaky=0.1) self.trans2 = nn.Sequential(nn.Conv2d(2,3,3), nn.Sigmoid()) self.conv6 = nn.Sequential(self.encoder2.conv1, self.encoder2.bn1, self.encoder2.relu, self.pool) self.conv7 = self.encoder2.layer1 self.conv8 = self.encoder2.layer2 self.conv9 = self.encoder2.layer3 self.conv10 = self.encoder2.layer4 self.avgpool2 = self.encoder2.avgpool self.fc2=nn.Linear(in_features=512, out_features=data.c, bias=True) # self.ReLU=nn.ReLU(inplace=True) def forward(self, x): conv1 = self.conv1(x) conv2 = self.conv2(conv1) conv3 = self.conv3(conv2) conv4 = self.conv4(conv3) conv5 = self.conv5(conv4) # print(conv5.shape) out1=self.avgpool(conv5) out1 = out1.reshape(out1.size(0), -1) out1=self.fc(out1) center = self.center(self.pool(conv5)) # print(center.shape) dec5 = self.dec5(torch.cat([center, conv5], 1)) # print(dec5.shape) dec4 = self.dec4(torch.cat([dec5, conv4], 1)) # print(dec4.shape) dec3 = self.dec3(torch.cat([dec4, conv3], 1)) # print(dec3.shape) dec2 = self.dec2(torch.cat([dec3, conv2], 1)) # print(dec2.shape) dec1 = self.dec1(dec2) # print(dec1.shape) dec0 = self.dec0(dec1) newx=self.trans2(self.trans(dec0)) conv6 = self.conv6(newx) conv6 = self.conv7(conv6) conv6 = self.conv8(conv6) conv6 = self.conv9(conv6) conv6 = self.conv10(conv6) out2=self.avgpool2(conv6) out2 = out2.reshape(out2.size(0), -1) out2=self.fc2(out2) return out1,out2 . class FeatureLoss(nn.Module): def __init__(self,): super().__init__() self.metric_names = [&#39;aloss&#39;,&#39;bloss&#39;] self.aloss=CrossEntropyFlat() # self.bloss=nn.CosineSimilarity(dim=1, eps=1e-6) def forward(self, input, target): target=target.long() aloss=self.aloss(input[0],target) bloss=self.aloss(input[1],target) # bloss=torch.sigmoid(input[1]) # bloss=bloss[range(len(target)),target].mean() loss=0.4*aloss+0.6*bloss outloss=[aloss,bloss] self.metrics=dict(zip(self.metric_names,outloss)) return loss def newacc(input, target): return accuracy(input[0],target) . gc.collect() learn=None model=None learn=Learner(data,model=UnetResnet34(),loss_func=FeatureLoss(),metrics=newacc,callback_fns=LossMetrics).to_fp16() . learn.unfreeze() . learn.lr_find() learn.recorder.plot() . &lt;progress value=&#39;0&#39; class=&#39;&#39; max=&#39;1&#39;, style=&#39;width:300px; height:20px; vertical-align: middle;&#39;&gt;&lt;/progress&gt; 0.00% [0/1 00:00&lt;00:00] epoch train_loss valid_loss newacc aloss bloss time . &lt;progress value=&#39;68&#39; class=&#39;&#39; max=&#39;5430&#39;, style=&#39;width:300px; height:20px; vertical-align: middle;&#39;&gt;&lt;/progress&gt; 1.25% [68/5430 00:32&lt;42:12 4.0015] &lt;/div&gt; &lt;/div&gt; LR Finder is complete, type {learner_name}.recorder.plot() to see the graph. . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; learn.fit_one_cycle(10,slice(1e-4)) . &lt;progress value=&#39;1&#39; class=&#39;&#39; max=&#39;10&#39;, style=&#39;width:300px; height:20px; vertical-align: middle;&#39;&gt;&lt;/progress&gt; 10.00% [1/10 43:15&lt;6:29:23] epoch train_loss valid_loss newacc aloss bloss time . 0 | 0.367547 | 0.203598 | 0.967959 | 0.109763 | 0.266155 | 43:15 | . &lt;progress value=&#39;2237&#39; class=&#39;&#39; max=&#39;5430&#39;, style=&#39;width:300px; height:20px; vertical-align: middle;&#39;&gt;&lt;/progress&gt; 41.20% [2237/5430 17:17&lt;24:41 0.3308] &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; learn.save(&#39;leaf&#39;) . learn.recorder.plot_losses() . from fastai.callbacks.hooks import * . i=np.random.randint(9431) #40 test=data.train_ds[i] sz = list(test[0].shape[-2:]) . xb,_ = data.one_item(test[0], detach=False, denorm=False) xb=xb.float() . m =learn.model.eval().float() . layer1=m.trans with hook_output(layer1) as hook_a: preds = m(xb) . plt.imshow(test[0].data.numpy().transpose(1,2,0)) plt.show() # plt.imshow(hook_a.stored[0,1]) . hook_a.stored.shape . torch.Size([1, 2, 256, 256]) . plt.imshow(hook_a.stored[0,0].cpu()) . &lt;matplotlib.image.AxesImage at 0x7f65fabd1390&gt; . &lt;/div&gt; .",
            "url": "https://robeson1010.github.io/robeson/jupyter/2020/08/09/Teacher.html",
            "relUrl": "/jupyter/2020/08/09/Teacher.html",
            "date": " • Aug 9, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "COVID-19 Infection and Lung Segmentation",
            "content": "Segmentation on CAMVID dataset . In this work, a public COVID-19 xray dataset was selected.This dataset contains 6500 images of AP/PA chest x-rays with pixel-level polygonal lung segmentations. There are 517 cases of COVID-19 amongst these. Use the command below to download only images presenting COVID-19. . Each image contains: . Two &quot;Lung&quot; segmentation masks (rendered as polygons, including the posterior region behind the heart). | A tag for the type of pneumonia (viral, bacterial, fungal, healthy/none). If the patient has COVID-19, additional tags stating age, sex, temperature, location, intubation status, ICU admission, and patient outcome. | Preprocessing . The origin Lung annotations are polygons following pixel-level boundaries. The data was saved as json file. In this part, we have to transfer the json polygons to png file . filelist=get_files(&#39;/home/staff/xin/scratch/COVID/covid-19-chest-x-ray-dataset/releases/all-images/annotations/&#39;,extensions=&#39;.json&#39;) . annpath=&#39;/home/staff/xin/scratch/COVID/label/&#39; . for file in tqdm.tqdm(filelist): with open(file) as f: data = json.load(f) annotations = list(filter(None, map(parse_darwin_annotation, data[&quot;annotations&quot;]))) # annotation_classes = [annotation.annotation_class for annotation in annotations] label=1 xx=np.zeros((data[&#39;image&#39;][&#39;height&#39;],data[&#39;image&#39;][&#39;width&#39;]),dtype=&#39;uint8&#39;) for annotation in annotations: classvalue=annotation.annotation_class if classvalue.name==&#39;Lung&#39;: xx+=convert_polygons_to_mask(annotation.data[&#39;path&#39;],height=data[&#39;image&#39;][&#39;height&#39;],width=data[&#39;image&#39;][&#39;width&#39;]) if classvalue.name==&#39;COVID-19&#39;: label=2 xx=xx*label newfilename=annpath+file.name.replace(&#39;json&#39;,&#39;png&#39;) io.imsave(newfilename,xx) . 100%|██████████| 6504/6504 [03:43&lt;00:00, 29.15it/s] . Show the data . After transfer the data, we display the dataset Here: . Code 1 = normal Lung | Code 2 = COVID Lung | datapath=&#39;/home/staff/xin/scratch/COVID/images/&#39; . def get_y_fn(x): return Path(str(x.parent).replace(&#39;images&#39;,&#39;label&#39;))/x.name.replace(&#39;jpeg&#39;,&#39;png&#39;).replace(&#39;jpg&#39;,&#39;png&#39;).replace(&#39;PNG&#39;,&#39;png&#39;).replace(&#39;JPG&#39;,&#39;png&#39;) codes = array([&#39;Background&#39;,&#39;Normal&#39;,&#39;COVID&#39;]) . src = (SegmentationItemList.from_folder(datapath).split_by_rand_pct().label_from_func(get_y_fn, classes=codes)) data = (src.transform(get_transforms(),size=256, tfm_y=True) .databunch(bs=8) .normalize(imagenet_stats)) . data.show_batch(rows=3,figsize=(10,10)) . Training and Validating the model . Based on our vision framework, the Unet with resnet18 was tested, The transfer learning was used to train the model. A mixed loss with dice and focalloss were used as the loss function in this work. . def dice_loss(input, target): input = torch.sigmoid(input) smooth = 1.0 iflat = input.view(-1) tflat = target.view(-1) intersection = (iflat * tflat).sum() return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth)) class FocalLoss(nn.Module): def __init__(self, gamma): super().__init__() self.gamma = gamma def forward(self, input, target): if not (target.size() == input.size()): raise ValueError(&quot;Target size ({}) must be the same as input size ({})&quot; .format(target.size(), input.size())) max_val = (-input).clamp(min=0) loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log() invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0)) loss = (invprobs * self.gamma).exp() * loss return loss.mean() class MixedLoss(nn.Module): def __init__(self, alpha, gamma): super().__init__() self.alpha = alpha self.focal = FocalLoss(gamma) def forward(self, input, target): # input=input.max() input=input[:,1,:,:].unsqueeze(1) target=target.float() loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target)) return loss.mean() def Iou(input, target): return dice(input,target,iou=True) . learn = unet_learner(data, models.resnet18, bottle=True,loss_func=MixedLoss(10.0, 2.0),metrics=[accuracy_thresh,dice,Iou],callback_fns=BnFreeze).to_fp16() . learn.summary() . DynamicUnet ====================================================================== Layer (type) Output Shape Param # Trainable ====================================================================== Conv2d [64, 128, 128] 9,408 False ______________________________________________________________________ BatchNorm2d [64, 128, 128] 128 True ______________________________________________________________________ ReLU [64, 128, 128] 0 False ______________________________________________________________________ MaxPool2d [64, 64, 64] 0 False ______________________________________________________________________ Conv2d [64, 64, 64] 36,864 False ______________________________________________________________________ BatchNorm2d [64, 64, 64] 128 True ______________________________________________________________________ ReLU [64, 64, 64] 0 False ______________________________________________________________________ Conv2d [64, 64, 64] 36,864 False ______________________________________________________________________ BatchNorm2d [64, 64, 64] 128 True ______________________________________________________________________ Conv2d [64, 64, 64] 36,864 False ______________________________________________________________________ BatchNorm2d [64, 64, 64] 128 True ______________________________________________________________________ ReLU [64, 64, 64] 0 False ______________________________________________________________________ Conv2d [64, 64, 64] 36,864 False ______________________________________________________________________ BatchNorm2d [64, 64, 64] 128 True ______________________________________________________________________ Conv2d [128, 32, 32] 73,728 False ______________________________________________________________________ BatchNorm2d [128, 32, 32] 256 True ______________________________________________________________________ ReLU [128, 32, 32] 0 False ______________________________________________________________________ Conv2d [128, 32, 32] 147,456 False ______________________________________________________________________ BatchNorm2d [128, 32, 32] 256 True ______________________________________________________________________ Conv2d [128, 32, 32] 8,192 False ______________________________________________________________________ BatchNorm2d [128, 32, 32] 256 True ______________________________________________________________________ Conv2d [128, 32, 32] 147,456 False ______________________________________________________________________ BatchNorm2d [128, 32, 32] 256 True ______________________________________________________________________ ReLU [128, 32, 32] 0 False ______________________________________________________________________ Conv2d [128, 32, 32] 147,456 False ______________________________________________________________________ BatchNorm2d [128, 32, 32] 256 True ______________________________________________________________________ Conv2d [256, 16, 16] 294,912 False ______________________________________________________________________ BatchNorm2d [256, 16, 16] 512 True ______________________________________________________________________ ReLU [256, 16, 16] 0 False ______________________________________________________________________ Conv2d [256, 16, 16] 589,824 False ______________________________________________________________________ BatchNorm2d [256, 16, 16] 512 True ______________________________________________________________________ Conv2d [256, 16, 16] 32,768 False ______________________________________________________________________ BatchNorm2d [256, 16, 16] 512 True ______________________________________________________________________ Conv2d [256, 16, 16] 589,824 False ______________________________________________________________________ BatchNorm2d [256, 16, 16] 512 True ______________________________________________________________________ ReLU [256, 16, 16] 0 False ______________________________________________________________________ Conv2d [256, 16, 16] 589,824 False ______________________________________________________________________ BatchNorm2d [256, 16, 16] 512 True ______________________________________________________________________ Conv2d [512, 8, 8] 1,179,648 False ______________________________________________________________________ BatchNorm2d [512, 8, 8] 1,024 True ______________________________________________________________________ ReLU [512, 8, 8] 0 False ______________________________________________________________________ Conv2d [512, 8, 8] 2,359,296 False ______________________________________________________________________ BatchNorm2d [512, 8, 8] 1,024 True ______________________________________________________________________ Conv2d [512, 8, 8] 131,072 False ______________________________________________________________________ BatchNorm2d [512, 8, 8] 1,024 True ______________________________________________________________________ Conv2d [512, 8, 8] 2,359,296 False ______________________________________________________________________ BatchNorm2d [512, 8, 8] 1,024 True ______________________________________________________________________ ReLU [512, 8, 8] 0 False ______________________________________________________________________ Conv2d [512, 8, 8] 2,359,296 False ______________________________________________________________________ BatchNorm2d [512, 8, 8] 1,024 True ______________________________________________________________________ BatchNorm2d [512, 8, 8] 1,024 True ______________________________________________________________________ ReLU [512, 8, 8] 0 False ______________________________________________________________________ Conv2d [1024, 8, 8] 4,719,616 True ______________________________________________________________________ ReLU [1024, 8, 8] 0 False ______________________________________________________________________ Conv2d [512, 8, 8] 4,719,104 True ______________________________________________________________________ ReLU [512, 8, 8] 0 False ______________________________________________________________________ Conv2d [1024, 8, 8] 525,312 True ______________________________________________________________________ PixelShuffle [256, 16, 16] 0 False ______________________________________________________________________ ReLU [1024, 8, 8] 0 False ______________________________________________________________________ BatchNorm2d [256, 16, 16] 512 True ______________________________________________________________________ Conv2d [512, 16, 16] 2,359,808 True ______________________________________________________________________ ReLU [512, 16, 16] 0 False ______________________________________________________________________ Conv2d [512, 16, 16] 2,359,808 True ______________________________________________________________________ ReLU [512, 16, 16] 0 False ______________________________________________________________________ ReLU [512, 16, 16] 0 False ______________________________________________________________________ Conv2d [1024, 16, 16] 525,312 True ______________________________________________________________________ PixelShuffle [256, 32, 32] 0 False ______________________________________________________________________ ReLU [1024, 16, 16] 0 False ______________________________________________________________________ BatchNorm2d [128, 32, 32] 256 True ______________________________________________________________________ Conv2d [384, 32, 32] 1,327,488 True ______________________________________________________________________ ReLU [384, 32, 32] 0 False ______________________________________________________________________ Conv2d [384, 32, 32] 1,327,488 True ______________________________________________________________________ ReLU [384, 32, 32] 0 False ______________________________________________________________________ ReLU [384, 32, 32] 0 False ______________________________________________________________________ Conv2d [768, 32, 32] 295,680 True ______________________________________________________________________ PixelShuffle [192, 64, 64] 0 False ______________________________________________________________________ ReLU [768, 32, 32] 0 False ______________________________________________________________________ BatchNorm2d [64, 64, 64] 128 True ______________________________________________________________________ Conv2d [256, 64, 64] 590,080 True ______________________________________________________________________ ReLU [256, 64, 64] 0 False ______________________________________________________________________ Conv2d [256, 64, 64] 590,080 True ______________________________________________________________________ ReLU [256, 64, 64] 0 False ______________________________________________________________________ ReLU [256, 64, 64] 0 False ______________________________________________________________________ Conv2d [512, 64, 64] 131,584 True ______________________________________________________________________ PixelShuffle [128, 128, 128] 0 False ______________________________________________________________________ ReLU [512, 64, 64] 0 False ______________________________________________________________________ BatchNorm2d [64, 128, 128] 128 True ______________________________________________________________________ Conv2d [96, 128, 128] 165,984 True ______________________________________________________________________ ReLU [96, 128, 128] 0 False ______________________________________________________________________ Conv2d [96, 128, 128] 83,040 True ______________________________________________________________________ ReLU [96, 128, 128] 0 False ______________________________________________________________________ ReLU [192, 128, 128] 0 False ______________________________________________________________________ Conv2d [384, 128, 128] 37,248 True ______________________________________________________________________ PixelShuffle [96, 256, 256] 0 False ______________________________________________________________________ ReLU [384, 128, 128] 0 False ______________________________________________________________________ MergeLayer [99, 256, 256] 0 False ______________________________________________________________________ Conv2d [49, 256, 256] 43,708 True ______________________________________________________________________ ReLU [49, 256, 256] 0 False ______________________________________________________________________ Conv2d [99, 256, 256] 43,758 True ______________________________________________________________________ ReLU [99, 256, 256] 0 False ______________________________________________________________________ MergeLayer [99, 256, 256] 0 False ______________________________________________________________________ Conv2d [3, 256, 256] 300 True ______________________________________________________________________ Total params: 31,023,958 Total trainable params: 19,857,046 Total non-trainable params: 11,166,912 Optimized with &#39;torch.optim.adam.Adam&#39;, betas=(0.9, 0.99) Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ Loss function : MixedLoss ====================================================================== Callbacks functions applied MixedPrecision . # transfer learnning with the imgnet weight learn.fit_one_cycle(4, slice(1e-4), pct_start=0.8) . epoch train_loss valid_loss accuracy_thresh dice Iou time . 0 | 0.698277 | 0.600837 | 0.672496 | 0.179343 | 0.100926 | 01:43 | . 1 | 0.560393 | 0.460410 | 0.737885 | 0.428270 | 0.280562 | 01:38 | . 2 | 0.454028 | 0.390147 | 0.739791 | 0.442059 | 0.292221 | 01:38 | . 3 | 0.350524 | 0.341719 | 0.744412 | 0.442989 | 0.292627 | 01:38 | . # save the model learn.save(&#39;stage-1&#39;) . learn.unfreeze() . learn.fit_one_cycle(12, lrs, pct_start=0.8) . epoch train_loss valid_loss accuracy_thresh dice Iou time . 0 | 0.360206 | 0.349642 | 0.743417 | 0.443168 | 0.292726 | 01:42 | . 1 | 0.368092 | 0.341796 | 0.742776 | 0.441587 | 0.291349 | 01:43 | . 2 | 0.352880 | 0.335430 | 0.742954 | 0.442194 | 0.291866 | 01:43 | . 3 | 0.342617 | 0.351400 | 0.744324 | 0.441858 | 0.291730 | 01:43 | . 4 | 0.343017 | 0.352271 | 0.741060 | 0.440586 | 0.290417 | 01:43 | . 5 | 0.347752 | 0.341524 | 0.742002 | 0.445484 | 0.294820 | 01:43 | . 6 | 0.335483 | 0.397091 | 0.741813 | 0.443230 | 0.292983 | 01:43 | . 7 | 0.318316 | 0.367886 | 0.739216 | 0.444838 | 0.294343 | 01:43 | . 8 | 0.331453 | 0.328769 | 0.736564 | 0.444368 | 0.293887 | 01:43 | . 9 | 0.324517 | 0.327686 | 0.734690 | 0.442461 | 0.292007 | 01:43 | . 10 | 0.307050 | 0.359769 | 0.741005 | 0.447669 | 0.296986 | 01:43 | . 11 | 0.315226 | 0.359217 | 0.740689 | 0.446886 | 0.296240 | 01:43 | . # save the model learn.save(&#39;stage-2&#39;); . Show result . learn.show_results() .",
            "url": "https://robeson1010.github.io/robeson/jupyter/2020/07/27/Covid.html",
            "relUrl": "/jupyter/2020/07/27/Covid.html",
            "date": " • Jul 27, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Segmentation",
            "content": "Segmentation on CAMVID dataset . Setup datablock . # Set up dataset path = untar_data(URLs.CAMVID) path.ls() . [PosixPath(&#39;/home/staff/xin/.fastai/data/camvid/valid.txt&#39;), PosixPath(&#39;/home/staff/xin/.fastai/data/camvid/labels&#39;), PosixPath(&#39;/home/staff/xin/.fastai/data/camvid/images&#39;), PosixPath(&#39;/home/staff/xin/.fastai/data/camvid/codes.txt&#39;)] . path_lbl = path/&#39;labels&#39; path_img = path/&#39;images&#39; bs=8 . fnames = get_image_files(path_img) lbl_names = get_image_files(path_lbl) get_y_fn = lambda x: path_lbl/f&#39;{x.stem}_P{x.suffix}&#39; codes = np.loadtxt(path/&#39;codes.txt&#39;, dtype=str); codes . array([&#39;Animal&#39;, &#39;Archway&#39;, &#39;Bicyclist&#39;, &#39;Bridge&#39;, &#39;Building&#39;, &#39;Car&#39;, &#39;CartLuggagePram&#39;, &#39;Child&#39;, &#39;Column_Pole&#39;, &#39;Fence&#39;, &#39;LaneMkgsDriv&#39;, &#39;LaneMkgsNonDriv&#39;, &#39;Misc_Text&#39;, &#39;MotorcycleScooter&#39;, &#39;OtherMoving&#39;, &#39;ParkingBlock&#39;, &#39;Pedestrian&#39;, &#39;Road&#39;, &#39;RoadShoulder&#39;, &#39;Sidewalk&#39;, &#39;SignSymbol&#39;, &#39;Sky&#39;, &#39;SUVPickupTruck&#39;, &#39;TrafficCone&#39;, &#39;TrafficLight&#39;, &#39;Train&#39;, &#39;Tree&#39;, &#39;Truck_Bus&#39;, &#39;Tunnel&#39;, &#39;VegetationMisc&#39;, &#39;Void&#39;, &#39;Wall&#39;], dtype=&#39;&lt;U17&#39;) . src = (SegmentationItemList.from_folder(path_img) .split_by_fname_file(&#39;../valid.txt&#39;) .label_from_func(get_y_fn, classes=codes)) . data = (src.transform(get_transforms(), size=256, tfm_y=True) .databunch(bs=bs) .normalize(imagenet_stats)) . data.show_batch(2, figsize=(10,7)) . Training . Model:Unet Backbone:Resnet34 . # define evaluation method name2id = {v:k for k,v in enumerate(codes)} void_code = name2id[&#39;Void&#39;] def acc_camvid(input, target): target = target.squeeze(1) mask = target != void_code return (input.argmax(dim=1)[mask]==target[mask]).float().mean() . learn = unet_learner(data, models.resnet34, metrics=acc_camvid) . learn.model . DynamicUnet( (layers): ModuleList( (0): Sequential( (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (4): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (5): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (6): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (4): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (5): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (7): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) ) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() (3): Sequential( (0): Sequential( (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (1): Sequential( (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) ) (4): UnetBlock( (shuf): PixelShuffle_ICNR( (conv): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1)) ) (shuf): PixelShuffle(upscale_factor=2) (pad): ReplicationPad2d((1, 0, 1, 0)) (blur): AvgPool2d(kernel_size=2, stride=1, padding=0) (relu): ReLU(inplace=True) ) (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv1): Sequential( (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (conv2): Sequential( (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (relu): ReLU() ) (5): UnetBlock( (shuf): PixelShuffle_ICNR( (conv): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1)) ) (shuf): PixelShuffle(upscale_factor=2) (pad): ReplicationPad2d((1, 0, 1, 0)) (blur): AvgPool2d(kernel_size=2, stride=1, padding=0) (relu): ReLU(inplace=True) ) (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv1): Sequential( (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (conv2): Sequential( (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (relu): ReLU() ) (6): UnetBlock( (shuf): PixelShuffle_ICNR( (conv): Sequential( (0): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1)) ) (shuf): PixelShuffle(upscale_factor=2) (pad): ReplicationPad2d((1, 0, 1, 0)) (blur): AvgPool2d(kernel_size=2, stride=1, padding=0) (relu): ReLU(inplace=True) ) (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv1): Sequential( (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (conv2): Sequential( (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (relu): ReLU() ) (7): UnetBlock( (shuf): PixelShuffle_ICNR( (conv): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1)) ) (shuf): PixelShuffle(upscale_factor=2) (pad): ReplicationPad2d((1, 0, 1, 0)) (blur): AvgPool2d(kernel_size=2, stride=1, padding=0) (relu): ReLU(inplace=True) ) (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv1): Sequential( (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (conv2): Sequential( (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (relu): ReLU() ) (8): PixelShuffle_ICNR( (conv): Sequential( (0): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1)) ) (shuf): PixelShuffle(upscale_factor=2) (pad): ReplicationPad2d((1, 0, 1, 0)) (blur): AvgPool2d(kernel_size=2, stride=1, padding=0) (relu): ReLU(inplace=True) ) (9): MergeLayer() (10): SequentialEx( (layers): ModuleList( (0): Sequential( (0): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (1): Sequential( (0): Conv2d(99, 99, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace=True) ) (2): MergeLayer() ) ) (11): Sequential( (0): Conv2d(99, 32, kernel_size=(1, 1), stride=(1, 1)) ) ) ) . # learn rate=1e-3 learn.fit_one_cycle(10, slice(1e-3), pct_start=0.9) . epoch train_loss valid_loss acc_camvid time . 0 | 0.903016 | 0.781723 | 0.813929 | 00:17 | . 1 | 0.773774 | 0.655938 | 0.832257 | 00:15 | . 2 | 0.691945 | 0.640359 | 0.835028 | 00:15 | . 3 | 0.634440 | 0.536892 | 0.855570 | 00:15 | . 4 | 0.580426 | 0.523467 | 0.851547 | 00:16 | . 5 | 0.548163 | 0.545224 | 0.848153 | 00:15 | . 6 | 0.558745 | 0.452550 | 0.876103 | 00:15 | . 7 | 0.500589 | 0.422394 | 0.884405 | 00:16 | . 8 | 0.493151 | 0.376440 | 0.895315 | 00:16 | . 9 | 0.416614 | 0.341692 | 0.900089 | 00:15 | . Results . learn.show_results(rows=5, figsize=(8,15)) .",
            "url": "https://robeson1010.github.io/robeson/jupyter/2020/07/20/segmentation.html",
            "relUrl": "/jupyter/2020/07/20/segmentation.html",
            "date": " • Jul 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Classfication",
            "content": "Binary classification . Download dataset . path = untar_data(URLs.PETS); path . Downloading https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet . PosixPath(&#39;/home/staff/xin/.fastai/data/oxford-iiit-pet&#39;) . Set up datablock . # setup batchsize as 64 path_img = path/&#39;images&#39; fnames = get_image_files(path_img) pat = r&#39;/([^/]+)_ d+.jpg$&#39; bs=64 data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=224, bs=bs ).normalize(imagenet_stats) . NameError Traceback (most recent call last) &lt;ipython-input-1-b951f86e420e&gt; in &lt;module&gt; -&gt; 1 path = untar_data(URLs.CAMVID) 2 path.ls() NameError: name &#39;untar_data&#39; is not defined . data.show_batch(rows=3, figsize=(7,6)) . Training: resnet34 . We will train for 4 epochs (4 cycles through all our data). . learn = cnn_learner(data, models.resnet34, metrics=error_rate) learn.model . Sequential( (0): Sequential( (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU(inplace=True) (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (4): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (1): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (5): Sequential( (0): BasicBlock( (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (6): Sequential( (0): BasicBlock( (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (3): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (4): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (5): BasicBlock( (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (7): Sequential( (0): BasicBlock( (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) (2): BasicBlock( (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) ) (1): Sequential( (0): AdaptiveConcatPool2d( (ap): AdaptiveAvgPool2d(output_size=1) (mp): AdaptiveMaxPool2d(output_size=1) ) (1): Flatten() (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (3): Dropout(p=0.25, inplace=False) (4): Linear(in_features=1024, out_features=512, bias=True) (5): ReLU(inplace=True) (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (7): Dropout(p=0.5, inplace=False) (8): Linear(in_features=512, out_features=37, bias=True) ) ) . learn.fit_one_cycle(4) . epoch train_loss valid_loss error_rate time . 0 | 1.415601 | 0.416884 | 0.131258 | 00:15 | . 1 | 0.630525 | 0.303163 | 0.104195 | 00:14 | . 2 | 0.384608 | 0.223384 | 0.075101 | 00:14 | . 3 | 0.283689 | 0.209493 | 0.067659 | 00:15 | . Results . We will first see which were the categories that the model most confused with one another. We will try to see if what the model predicted was reasonable or not. In this case the mistakes look reasonable (none of the mistakes seems obviously naive). This is an indicator that our classifier is working correctly. . Furthermore, when we plot the confusion matrix, we can see that the distribution is heavily skewed: the model makes the same mistakes over and over again but it rarely confuses other categories. . interp = ClassificationInterpretation.from_learner(learn) losses,idxs = interp.top_losses() . interp.plot_top_losses(9, figsize=(15,11)) . interp.plot_confusion_matrix(figsize=(12,12), dpi=60) .",
            "url": "https://robeson1010.github.io/robeson/jupyter/2020/07/19/classification.html",
            "relUrl": "/jupyter/2020/07/19/classification.html",
            "date": " • Jul 19, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Vision framework",
            "content": "Installation and updating . To install or update the framework, we recommend pip: . pip install mmuvision . Creating a custom dataset . The data block API lets you customize the creation of a DataBunch by isolating the underlying parts of that process in separate blocks, mainly: . Where are the inputs and how to create them? How to split the data into a training and validation sets? How to label the inputs? What transforms to apply? How to add a test set? How to wrap in dataloaders and create the DataBunch? Each of these may be addressed with a specific block designed for your unique setup. Your inputs might be in a folder, a csv file, or a dataframe. You may want to split them randomly, by certain indices or depending on the folder they are in. You can have your labels in your csv file or your dataframe, but it may come from folders or a specific function of the input. You may choose to add data augmentation or not. A test set is optional too. Finally you have to set the arguments to put the data together in a DataBunch (batch size, collate function...) . The data block API is called as such because you can mix and match each one of those blocks with the others, allowing for a total flexibility to create your customized DataBunch for training, validation and testing. The factory methods of the various DataBunch are great for beginners but you can&#39;t always make your data fit in the tracks they require. . Creating a custom or existing model . Creating a custom loss . Trainning model . Model evaluation .",
            "url": "https://robeson1010.github.io/robeson/jupyter/2020/07/18/Introduction.html",
            "relUrl": "/jupyter/2020/07/18/Introduction.html",
            "date": " • Jul 18, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://robeson1010.github.io/robeson/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://robeson1010.github.io/robeson/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://robeson1010.github.io/robeson/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}